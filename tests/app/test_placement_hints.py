"""test app/placement_hints"""
import json
from pathlib import Path

import numpy as np
import numpy.testing as npt
from click.testing import CliRunner
from voxcell import VoxelData  # type: ignore

import atlas_building_tools.app.placement_hints as tested
from tests.placement_hints.mocking_tools import ThalamusMock


def test_thalamus():
    runner = CliRunner()
    with runner.isolated_filesystem():
        thalamus_mock = ThalamusMock(padding=10, shape=(60, 50, 60), layer_thickness_ratio=0.15)
        direction_vectors = np.zeros(thalamus_mock.annotation.raw.shape + (3,), dtype=float)
        direction_vectors[thalamus_mock.annotation.raw > 0] = (-1.0, 0.0, 0.0)

        thalamus_mock.annotation.save_nrrd("annotation.nrrd")
        thalamus_mock.annotation.with_data(direction_vectors).save_nrrd("direction_vectors.nrrd")
        with open("hierarchy.json", "w") as file_:
            json.dump(thalamus_mock.region_map_dict, file_)

        result = runner.invoke(
            tested.thalamus,
            [
                "--annotation-path",
                "annotation.nrrd",
                "--hierarchy-path",
                "hierarchy.json",
                "--direction-vectors-path",
                "direction_vectors.nrrd",
                "--output-dir",
                "placement_hints",
            ],
        )
        assert result.exit_code == 0

        # The values selected below as upper bounds are surprisingly large, which can be explained
        # as follows. Due to the shape and the size of the simplified brain region under test,
        # voxels close to the boundary of the volume are problematic (rays issued from them
        # all miss the top surface meshes which have a too low resolution). This problem is
        # aggravated by the splitting into two hemispheres. Increasing the dimensions of the tested
        # volume reduces the number of problematic voxels but makes the test much longer.
        # See for a picture of the problematic voxel volume generated by this test.
        #
        # The testing issues reported here are very similar to those encountered with CA1 and isocortex in
        # tests/placement_hints. Renderings of the created surface meshes and of problematic volumes
        # indicate that the algorithms are working as expected.

        with open("placement_hints/distance_report.json") as file_:
            report = json.load(file_)
            distances_report = report["before interpolation"]
            assert (
                distances_report[
                    "Proportion of voxels whose rays make an obtuse"
                    " angle with the mesh normal at the intersection point"
                ]
                <= 0.15
            )
            del distances_report[
                "Proportion of voxels whose rays make an obtuse"
                " angle with the mesh normal at the intersection point"
            ]

            assert (
                distances_report["Proportion of voxels with at least one distance-related problem"]
                < 0.5
            )
            del distances_report["Proportion of voxels with at least one distance-related problem"]

            for proportion in distances_report.values():
                assert proportion <= 0.45

        problematic_volume = VoxelData.load_nrrd("placement_hints/TH_problematic_voxel_mask.nrrd")
        # Problems reported before interpolation of faulty values
        assert np.count_nonzero(problematic_volume.raw == 1) / thalamus_mock.volume < 0.5
        # Problems which have persisted after interpolation
        assert np.count_nonzero(problematic_volume.raw == 2) / thalamus_mock.volume < 0.4
